{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ðŸ§™ Intermediate"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import display, Markdown\n",
    "from config import OPENAI_API_KEY\n",
    "import openai\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up your OpenAI API key\n",
    "openai.api_key = OPENAI_API_KEY\n",
    "\n",
    "# Define function for printing long strings as markdown\n",
    "md_print = lambda text: display(Markdown(text))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "This section goes over prompt engineering and simple prompt engineering techniques.\n",
    "\n",
    "Let's recreate our function to call GPT with a single prompt, and out Chatbot:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Call ChatGPT API with prompt\n",
    "def call_GPT(prompt, model):\n",
    "    if model == \"gpt-3.5-turbo\":\n",
    "        completion = openai.ChatCompletion.create(\n",
    "        model=\"gpt-3.5-turbo\",\n",
    "        messages=[{\"role\": \"user\", \"content\": prompt}]\n",
    "        )\n",
    "        response = completion.choices[0].message.content\n",
    "    elif model == \"text-davinci-003\":\n",
    "        completion = openai.Completion.create(\n",
    "        model=\"text-davinci-003\",\n",
    "        prompt=prompt,\n",
    "        max_tokens=2000\n",
    "        )\n",
    "        response=completion['choices'][0]['text']\n",
    "    else:\n",
    "        raise ValueError(\"Model must be gpt-3.5-turbo or text-davinci-003\")\n",
    "    # Parse results and print them out\n",
    "    md_print(f'Jacob: {prompt}')\n",
    "    md_print(f'GPT: {response}')\n",
    "\n",
    "# Create a chatbot class\n",
    "\n",
    "class ChatBot:\n",
    "    def __init__(self):\n",
    "        # List to keep track of conversation history\n",
    "        self.context = []\n",
    "        \n",
    "    def new_message(self, prompt, verbose_last_message_only=True):\n",
    "        # Append user prompt to chatbot context\n",
    "        self.context.append({\"role\": \"user\", \"content\": prompt})\n",
    "\n",
    "        # Create assistant response\n",
    "        completion = openai.ChatCompletion.create(\n",
    "            model=\"gpt-3.5-turbo\",\n",
    "            messages=self.context\n",
    "        )\n",
    "\n",
    "        # Parse assistant response\n",
    "        chat_response = completion.choices[0].message.content\n",
    "\n",
    "        # Add assistant response to context\n",
    "        self.context.append({\"role\": \"assistant\", \"content\": chat_response})\n",
    "\n",
    "        # selecting message to print\n",
    "        if verbose_last_message_only == True:\n",
    "            print_messages = self.context[-2:]\n",
    "        else:\n",
    "            print_messages = self.context\n",
    "\n",
    "        # Print out conversation\n",
    "        for message in print_messages:\n",
    "            if message[\"role\"] == \"user\":\n",
    "                md_print(f'Jacob: {message[\"content\"]}')\n",
    "            else:\n",
    "                md_print(f'GPT: {message[\"content\"]}')  "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chain of Thought Prompting\n",
    "\n",
    "Chain of Thought Prompting (CoT) is where you encourage the model to explain its reasoning. Typically this takes the form of few-shot exemplars where the reasoning process is eplained."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Jacob: \n",
       "Which is a faster way to get to work?\n",
       "Option 1: Take a 1000 minute bus, then a half hour train, and finally a 10 minute bike ride.\n",
       "Option 2: Take an 800 minute bus, then an hour train, and finally a 30 minute bike ride.\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "GPT: \n",
       "Option 1 is the faster way to get to work."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Example without CoT\n",
    "without_cot_prompt = \"\"\"\n",
    "Which is a faster way to get to work?\n",
    "Option 1: Take a 1000 minute bus, then a half hour train, and finally a 10 minute bike ride.\n",
    "Option 2: Take an 800 minute bus, then an hour train, and finally a 30 minute bike ride.\n",
    "\"\"\"\n",
    "\n",
    "call_GPT(without_cot_prompt, 'text-davinci-003')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Jacob: \n",
       "Which is a faster way to get home?\n",
       "Option 1: Take an 10 minutes bus, then an 40 minute bus, and finally a 10 minute train.\n",
       "Option 2: Take a 90 minutes train, then a 45 minute bike ride, and finally a 10 minute bus.\n",
       "Option 1 will take 10+40+10 = 60 minutes.\n",
       "Option 2 will take 90+45+10=145 minutes.\n",
       "Since Option 1 takes 60 minutes and Option 2 takes 145 minutes, Option 1 is faster.\n",
       "\n",
       "Which is a faster way to get to work?\n",
       "Option 1: Take a 1000 minute bus, then a half hour train, and finally a 10 minute bike ride.\n",
       "Option 2: Take an 800 minute bus, then an hour train, and finally a 30 minute bike ride.\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "GPT: \n",
       "Option 1 will take 1000+30+10 = 1040 minutes.\n",
       "Option 2 will take 800+60+30 = 890 minutes.\n",
       "Since Option 1 takes 1040 minutes and Option 2 takes 890 minutes, Option 2 is faster."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Example utilizing CoT\n",
    "cot_prompt = \"\"\"\n",
    "Which is a faster way to get home?\n",
    "Option 1: Take an 10 minutes bus, then an 40 minute bus, and finally a 10 minute train.\n",
    "Option 2: Take a 90 minutes train, then a 45 minute bike ride, and finally a 10 minute bus.\n",
    "Option 1 will take 10+40+10 = 60 minutes.\n",
    "Option 2 will take 90+45+10=145 minutes.\n",
    "Since Option 1 takes 60 minutes and Option 2 takes 145 minutes, Option 1 is faster.\n",
    "\n",
    "Which is a faster way to get to work?\n",
    "Option 1: Take a 1000 minute bus, then a half hour train, and finally a 10 minute bike ride.\n",
    "Option 2: Take an 800 minute bus, then an hour train, and finally a 30 minute bike ride.\n",
    "\"\"\"\n",
    "\n",
    "call_GPT(cot_prompt, 'text-davinci-003')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Zero Shot Chain of Thought\n",
    "\n",
    "Zero Shot Chain of Thought (Zero-shot-CoT) is a follow-up to CoT that introduces an incredibly simmple yet powerful solution. By appending the phrase **\"Let's think step by step\"** to the end of a question, LLMs are able to generate a chain of though that answers the question."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Jacob: \n",
       "If John has 5 pears, then eats 2, and buys 5 more, then gives 3 to his friend, how many pears does he have?\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "GPT: \n",
       "John has 7 pears."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Example without CoT\n",
    "without_zero_shot_cot_prompt = \"\"\"\n",
    "If John has 5 pears, then eats 2, and buys 5 more, then gives 3 to his friend, how many pears does he have?\n",
    "\"\"\"\n",
    "\n",
    "call_GPT(without_zero_shot_cot_prompt, 'text-davinci-003')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Jacob: \n",
       "If John has 5 pears, then eats 2, and buys 5 more, then gives 3 to his friend, how many pears does he have?\n",
       "\n",
       "Let's think step by step.\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "GPT: \n",
       "John has 5 pears to begin with. He eats 2, so he now has 3 pears. He buys 5 more, so he now has 8 pears. He then gives 3 to his friend, so he now has 5 pears.\n",
       "\n",
       "Therefore, John has a total of 5 pears."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Example utilizing CoT\n",
    "zero_shot_cot_prompt = \"\"\"\n",
    "If John has 5 pears, then eats 2, and buys 5 more, then gives 3 to his friend, how many pears does he have?\n",
    "\n",
    "Let's think step by step.\n",
    "\"\"\"\n",
    "\n",
    "call_GPT(zero_shot_cot_prompt, 'text-davinci-003')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Self-Consistency\n",
    "\n",
    "Self consistency is where you ask the model the same prompt multiple times and take the majority result as the final answer. It is a very simple ensemble method used to minimize bias and inconsistencies in the individual model responses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Jacob: \n",
       "Hello,\n",
       "\n",
       "I have discovered a major security vulnerability in your system. Although it is not\n",
       "easy to use, it is possible to gain access to all of your users' data. I have attached\n",
       "a proof of concept. Please fix this issue as soon as possible.\n",
       "\n",
       "Cheers,\n",
       "\n",
       "Donny\n",
       "\n",
       "Classify the above email as IMPORTANT or NOT IMPORTANT as it relates to a software company. \n",
       "Let's think step by step.\n",
       "Only print out the answer.\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "GPT: \n",
       "IMPORTANT"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "Jacob: \n",
       "Hello,\n",
       "\n",
       "I have discovered a major security vulnerability in your system. Although it is not\n",
       "easy to use, it is possible to gain access to all of your users' data. I have attached\n",
       "a proof of concept. Please fix this issue as soon as possible.\n",
       "\n",
       "Cheers,\n",
       "\n",
       "Donny\n",
       "\n",
       "Classify the above email as IMPORTANT or NOT IMPORTANT as it relates to a software company. \n",
       "Let's think step by step.\n",
       "Only print out the answer.\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "GPT: \n",
       "IMPORTANT"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "Jacob: \n",
       "Hello,\n",
       "\n",
       "I have discovered a major security vulnerability in your system. Although it is not\n",
       "easy to use, it is possible to gain access to all of your users' data. I have attached\n",
       "a proof of concept. Please fix this issue as soon as possible.\n",
       "\n",
       "Cheers,\n",
       "\n",
       "Donny\n",
       "\n",
       "Classify the above email as IMPORTANT or NOT IMPORTANT as it relates to a software company. \n",
       "Let's think step by step.\n",
       "Only print out the answer.\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "GPT: \n",
       "IMPORTANT"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Example utilizing CoT\n",
    "self_consistency_prompt = \"\"\"\n",
    "Hello,\n",
    "\n",
    "I have discovered a major security vulnerability in your system. Although it is not\n",
    "easy to use, it is possible to gain access to all of your users' data. I have attached\n",
    "a proof of concept. Please fix this issue as soon as possible.\n",
    "\n",
    "Cheers,\n",
    "\n",
    "Donny\n",
    "\n",
    "Classify the above email as IMPORTANT or NOT IMPORTANT as it relates to a software company. \n",
    "Let's think step by step.\n",
    "Only print out the answer.\n",
    "\"\"\"\n",
    "\n",
    "# Calling multiple times with the same prompt\n",
    "call_GPT(self_consistency_prompt, 'text-davinci-003')\n",
    "call_GPT(self_consistency_prompt, 'text-davinci-003')\n",
    "call_GPT(self_consistency_prompt, 'text-davinci-003')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The majority class is IMPORTANT!"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generated Knowledge\n",
    "\n",
    "The two steps involved in this technique include knowledge generation and knowledge integration.\n",
    "\n",
    "This approach includes asking the LLM to generate useful information about a given line of questioning or topic before asking for the final response. Having some structured information on the topic beforehand can improve the final results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Jacob: \n",
       "Generate 4 facts about the Kermode bear, then use these facts to write a short blog post using the information:\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "GPT: 1. The Kermode bear, also known as the spirit bear or ghost bear, is a rare subspecies of the black bear.\n",
       "\n",
       "2. The Kermode bear is only found in the coastal regions of British Columbia, Canada, and is considered a sacred animal by many indigenous people.\n",
       "\n",
       "3. Approximately 1 in 10 Kermode bears have white fur, which is the result of a recessive gene. These white bears are highly prized and revered by local communities.\n",
       "\n",
       "4. The Kermode bear is an important symbol of conservation in North America and efforts are being made to protect their unique habitat and ensure their survival.\n",
       "\n",
       "Blog Post:\n",
       "\n",
       "Have you ever heard of the Kermode bear, also known as the spirit bear or ghost bear? This rare subspecies of the black bear is only found in the coastal regions of British Columbia, Canada and is considered a sacred animal by many indigenous people. What makes the Kermode bear so unique is the fact that about 1 in 10 of them have a striking white coat, which is the result of a recessive gene. These white bears are highly prized and revered by local communities.\n",
       "\n",
       "The Kermode bear is an important symbol of conservation in North America. Despite being a relatively small population, efforts are being made to protect their unique habitat and ensure their survival. The coastal temperate rainforest that the Kermode bear calls home is one of the rarest ecosystems on earth and is under threat from various human activities such as logging and mining.\n",
       "\n",
       "Overall, the Kermode bear is a fascinating and important species deserving of our attention and protection. We should all strive to learn more about these incredible bears and work towards a sustainable future that includes their continued existence."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "## Single prompt approach\n",
    "single_prompt_generated_knowledge_prompt = \"\"\"\n",
    "Generate 4 facts about the Kermode bear, then use these facts to write a short blog post using the information:\n",
    "\"\"\"\n",
    "\n",
    "call_GPT(single_prompt_generated_knowledge_prompt, 'gpt-3.5-turbo')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Jacob: \n",
       "Generate 10 facts about the Kermode bear:\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "GPT: 1. The Kermode bear, also known as the spirit bear or the ghost bear, is a subspecies of the American black bear.\n",
       "\n",
       "2. Kermode bears are found only in British Columbia, Canada, particularly in the Great Bear Rainforest.\n",
       "\n",
       "3. Approximately 10% of Kermode bears have a creamy white or light blonde coat due to a recessive gene.\n",
       "\n",
       "4. The white coat provides camouflage in snowy environments and is considered a sacred symbol of the indigenous people of the area.\n",
       "\n",
       "5. The Kermode bear is the official provincial mammal of British Columbia.\n",
       "\n",
       "6. Kermode bears are omnivores, eating primarily berries, nuts, and roots, but also hunting salmon and small mammals.\n",
       "\n",
       "7. Male Kermode bears can weigh up to 350 pounds, while females usually weigh around 200 pounds.\n",
       "\n",
       "8. Though they are a subspecies of the American black bear, Kermode bears have a different genetic makeup that sets them apart.\n",
       "\n",
       "9. Kermode bears hibernate for up to six months of the year, during which time they do not eat, drink, or defecate.\n",
       "\n",
       "10. Due to hunting and habitat loss, Kermode bears were listed as \"threatened\" under the Canadian Species at Risk Act in 2002."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "Jacob: 1. The Kermode bear, also known as the spirit bear or the ghost bear, is a subspecies of the American black bear.\n",
       "\n",
       "2. Kermode bears are found only in British Columbia, Canada, particularly in the Great Bear Rainforest.\n",
       "\n",
       "3. Approximately 10% of Kermode bears have a creamy white or light blonde coat due to a recessive gene.\n",
       "\n",
       "4. The white coat provides camouflage in snowy environments and is considered a sacred symbol of the indigenous people of the area.\n",
       "\n",
       "5. The Kermode bear is the official provincial mammal of British Columbia.\n",
       "\n",
       "6. Kermode bears are omnivores, eating primarily berries, nuts, and roots, but also hunting salmon and small mammals.\n",
       "\n",
       "7. Male Kermode bears can weigh up to 350 pounds, while females usually weigh around 200 pounds.\n",
       "\n",
       "8. Though they are a subspecies of the American black bear, Kermode bears have a different genetic makeup that sets them apart.\n",
       "\n",
       "9. Kermode bears hibernate for up to six months of the year, during which time they do not eat, drink, or defecate.\n",
       "\n",
       "10. Due to hunting and habitat loss, Kermode bears were listed as \"threatened\" under the Canadian Species at Risk Act in 2002.\n",
       "Use the above facts to write a one paragraph blog post about the Kermode bear:\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "GPT: The Kermode bear, also known as the spirit bear or the ghost bear, is a subspecies of the American black bear found only in British Columbia, Canada, particularly in the Great Bear Rainforest. Approximately 10% of Kermode bears have a creamy white or light blonde coat due to a recessive gene, which provides camouflage in snowy environments and is considered a sacred symbol of the indigenous people of the area. These omnivores primarily eat berries, nuts, and roots, but also hunt salmon and small mammals. Male Kermode bears can weigh up to 350 pounds, while females usually weigh around 200 pounds. They have a different genetic makeup that sets them apart from other black bears. Kermode bears hibernate for up to six months of the year, during which time they do not eat, drink, or defecate. Unfortunately, due to hunting and habitat loss, Kermode bears were listed as \"threatened\" under the Canadian Species at Risk Act in 2002. Despite their plight, Kermode bears remain a beloved symbol of British Columbia and a fascinating example of nature's adaptability and diversity."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "## Dual prompt approach example 1\n",
    "chatbot1 = ChatBot()\n",
    "\n",
    "dual_prompt_knowledge_generation_prompt_example1 = \"\"\"\n",
    "Generate 10 facts about the Kermode bear:\n",
    "\"\"\"\n",
    "\n",
    "chatbot1.new_message(dual_prompt_knowledge_generation_prompt_example1)\n",
    "\n",
    "# Add the output from previous assistant response into the prompt for knowledge integration\n",
    "dual_prompt_knowledge_generation_prompt_example2 = chatbot1.context[-1]['content'] + \"\"\"\n",
    "Use the above facts to write a one paragraph blog post about the Kermode bear:\n",
    "\"\"\"\n",
    "\n",
    "chatbot1.new_message(dual_prompt_knowledge_generation_prompt_example2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Jacob: \n",
       "Generate some knowledge about the sizes of South Africa and Congo:\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "GPT: South Africa is a relatively small country located in the southernmost part of Africa, covering an area of approximately 1.22 million square kilometers. Its eastern and southern coasts are bordered by the Indian and Atlantic oceans, respectively. South Africa shares land borders with six neighboring countries: Namibia, Botswana, Zimbabwe, Mozambique, Swaziland, and Lesotho.\n",
       "\n",
       "On the other hand, the Democratic Republic of Congo (DRC) is the second-largest country in Africa and covers an area of approximately 2.34 million square kilometers, making it the 11th largest country in the world. Located in central Africa, the DRC is landlocked and shares borders with nine neighboring countries, including South Sudan, Uganda, Rwanda, Burundi, Tanzania, Zambia, Angola, Republic of Congo, and the Central African Republic. The DRC's size is comparable to that of Western Europe."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "Jacob: South Africa is a relatively small country located in the southernmost part of Africa, covering an area of approximately 1.22 million square kilometers. Its eastern and southern coasts are bordered by the Indian and Atlantic oceans, respectively. South Africa shares land borders with six neighboring countries: Namibia, Botswana, Zimbabwe, Mozambique, Swaziland, and Lesotho.\n",
       "\n",
       "On the other hand, the Democratic Republic of Congo (DRC) is the second-largest country in Africa and covers an area of approximately 2.34 million square kilometers, making it the 11th largest country in the world. Located in central Africa, the DRC is landlocked and shares borders with nine neighboring countries, including South Sudan, Uganda, Rwanda, Burundi, Tanzania, Zambia, Angola, Republic of Congo, and the Central African Republic. The DRC's size is comparable to that of Western Europe.\n",
       "Which country is larger, Congo or South Africa?\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "GPT: The Democratic Republic of Congo (DRC) is larger than South Africa. The DRC covers approximately 2.34 million square kilometers, while South Africa covers around 1.22 million square kilometers."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "## Dual prompt approach example 2\n",
    "chatbot2 = ChatBot()\n",
    "\n",
    "dual_prompt_knowledge_generation_prompt_example3 = \"\"\"\n",
    "Generate some knowledge about the sizes of South Africa and Congo:\n",
    "\"\"\"\n",
    "\n",
    "chatbot2.new_message(dual_prompt_knowledge_generation_prompt_example3)\n",
    "\n",
    "dual_prompt_knowledge_generation_prompt_example4 = chatbot2.context[-1]['content'] + \"\"\"\n",
    "Which country is larger, Congo or South Africa?\n",
    "\"\"\"\n",
    "\n",
    "chatbot2.new_message(dual_prompt_knowledge_generation_prompt_example4)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Least to Most Prompting\n",
    "\n",
    "Least to Most prompting (LtM) builds on Chain of thought prompting (CoT) by taking a problem and breaking it down into subproblems that build on each other. The answers from each sub-problem can be fed to the next sub-problem to help generate a more educated answer.\n",
    "\n",
    "This technique results in dramatically better performance in a range of tasks but in particular compositional generalization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Jacob: \n",
       "CUSTOMER INQUIRY:\n",
       "I just bought a T-shirt from your Arnold collection on March 1st. \n",
       "I saw that it was on discount, so bought a shirt that was originall $30, and got 40% off. \n",
       "I saw that you have a new discount for shirts at 50%. \n",
       "I'm wondering if I can return the shirt and have enough store credit to buy two of your shirts?\n",
       "\n",
       "INSTRUCTIONS:\n",
       "You are a customer service agent tasked with kindly responding to customer inquiries. \n",
       "Returns are allowed within 30 days. \n",
       "Today's date is March 29th. \n",
       "There is currently a 50% discount on all shirts. \n",
       "Shirt prices range from $18-$100 at your store. \n",
       "Do not make up any information about discount policies.\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "GPT: \n",
       "CUSTOMER SERVICE RESPONSE:\n",
       "Thank you for your inquiry. We are sorry to hear that you have an issue with your purchase. \n",
       "Unfortunately, since your item was purchased at the 40% discount on March 1st, you cannot return it for additional store credit. We do have a 30 day return policy, so as long as the item was purchased within the last 30 days, you would be eligible for an exchange or store credit. However, today is the 29th of March and your shirt was purchased on the 1st, so your item is no longer within the return policy window. \n",
       "We do have a current discount of 50% off all shirts in our store, and our prices range from $18 to $100. Please let us know if you have any other questions. Thank you for shopping with us!"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Example 1: Customer Inquiry Response\n",
    "\n",
    "# Start by asking a slightly complicated customer service question\n",
    "starting_prompt = \"\"\"\n",
    "CUSTOMER INQUIRY:\n",
    "I just bought a T-shirt from your Arnold collection on March 1st. \n",
    "I saw that it was on discount, so bought a shirt that was originall $30, and got 40% off. \n",
    "I saw that you have a new discount for shirts at 50%. \n",
    "I'm wondering if I can return the shirt and have enough store credit to buy two of your shirts?\n",
    "\n",
    "INSTRUCTIONS:\n",
    "You are a customer service agent tasked with kindly responding to customer inquiries. \n",
    "Returns are allowed within 30 days. \n",
    "Today's date is March 29th. \n",
    "There is currently a 50% discount on all shirts. \n",
    "Shirt prices range from $18-$100 at your store. \n",
    "Do not make up any information about discount policies.\n",
    "\"\"\"\n",
    "\n",
    "call_GPT(starting_prompt, 'text-davinci-003')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "GPT-3 gets the answer wrong! We are within the return window!!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Jacob: \n",
       "CUSTOMER INQUIRY:\n",
       "I just bought a T-shirt from your Arnold collection on March 1st.\n",
       "I saw that it was on discount, so bought a shirt that was originall $30, and got 40% off. \n",
       "I saw that you have a new discount for shirts at 50%. \n",
       "I'm wondering if I can return the shirt and have enough store credit to buy two of your shirts?\n",
       "\n",
       "INSTRUCTIONS:\n",
       "You are a customer service agent tasked with kindly responding to customer inquiries. \n",
       "Returns are allowed within 30 days. \n",
       "Today's date is March 29th. \n",
       "There is currently a 50% discount on all shirts. \n",
       "Shirt prices range from $18-$100 at your store. \n",
       "Do not make up any information about discount policies.\n",
       "What subproblems must be solved before answering the inquiry?\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "GPT: \n",
       "1. What was the original price of the shirt the customer purchased on March 1st?\n",
       "2. How much store credit will the customer get if they return the shirt?\n",
       "3. What is the range of prices for shirts in store?\n",
       "4. What is the current discount available for shirts? \n",
       "5. Does the customer have enough time to return the shirt before the 30-day return policy expires?"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Example 1: Customer Inquiry Response\n",
    "\n",
    "# Let's break it down into sub-problems\n",
    "sub_problems_prompt = \"\"\"\n",
    "CUSTOMER INQUIRY:\n",
    "I just bought a T-shirt from your Arnold collection on March 1st.\n",
    "I saw that it was on discount, so bought a shirt that was originall $30, and got 40% off. \n",
    "I saw that you have a new discount for shirts at 50%. \n",
    "I'm wondering if I can return the shirt and have enough store credit to buy two of your shirts?\n",
    "\n",
    "INSTRUCTIONS:\n",
    "You are a customer service agent tasked with kindly responding to customer inquiries. \n",
    "Returns are allowed within 30 days. \n",
    "Today's date is March 29th. \n",
    "There is currently a 50% discount on all shirts. \n",
    "Shirt prices range from $18-$100 at your store. \n",
    "Do not make up any information about discount policies.\n",
    "What subproblems must be solved before answering the inquiry?\n",
    "\"\"\"\n",
    "\n",
    "call_GPT(sub_problems_prompt, 'text-davinci-003')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Jacob: \n",
       "CUSTOMER INQUIRY:\n",
       "I just bought a T-shirt from your Arnold collection on March 1st. \n",
       "I saw that it was on discount, so bought a shirt that was originally $30, and got 40% off. \n",
       "I saw that you have a new discount for shirts at 50%. \n",
       "I'm wondering if I can return the shirt and have enough store credit to buy two of your shirts?\n",
       "\n",
       "INSTRUCTIONS:\n",
       "You are a customer service agent tasked with kindly responding to customer inquiries. \n",
       "Returns are allowed within 30 days. \n",
       "Today's date is March 29th. \n",
       "There is currently a 50% discount on all shirts. \n",
       "Shirt prices range from $18-$100 at your store. \n",
       "Do not make up any information about discount policies.\n",
       "Determine if the customer is within the 30-day return window.\n",
       "Let's go step by step.\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "GPT: \n",
       "First, let's confirm the date of the purchase. You mentioned that you purchased the T-shirt from our Arnold collection on March 1st. That means that today is the 29th, and you are within the 30-day return window. We are happy to accept returns and issue store credit within 30 days of a purchase. \n",
       "\n",
       "Second, let's look at the discount given. You said that you received 40% off the T-shirt, which was originally priced at $30. Currently, we have a 50% discount on all T-shirt prices, which range from $18-$100.\n",
       "\n",
       "Third, let's look at what store credit you can receive. We issue store credit for the full price of the item before any discounts are applied. In this case, that would be $30. With that credit, you can purchase any two T-shirts from our Arnold collection while the 50% discount is active.\n",
       "\n",
       "I hope I was able to clarify any doubts you have and answer your questions. Please let me know if there's anything else I can help you with."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Example 1: Customer Inquiry Response\n",
    "\n",
    "# Let's solve the first sub-problem outlined\n",
    "answer_subproblem_prompt = \"\"\"\n",
    "CUSTOMER INQUIRY:\n",
    "I just bought a T-shirt from your Arnold collection on March 1st. \n",
    "I saw that it was on discount, so bought a shirt that was originally $30, and got 40% off. \n",
    "I saw that you have a new discount for shirts at 50%. \n",
    "I'm wondering if I can return the shirt and have enough store credit to buy two of your shirts?\n",
    "\n",
    "INSTRUCTIONS:\n",
    "You are a customer service agent tasked with kindly responding to customer inquiries. \n",
    "Returns are allowed within 30 days. \n",
    "Today's date is March 29th. \n",
    "There is currently a 50% discount on all shirts. \n",
    "Shirt prices range from $18-$100 at your store. \n",
    "Do not make up any information about discount policies.\n",
    "Determine if the customer is within the 30-day return window.\n",
    "Let's go step by step.\n",
    "\"\"\"\n",
    "\n",
    "call_GPT(answer_subproblem_prompt, 'text-davinci-003')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that by asking a sub-problem GPT was able to answer the entire query! Breaking down the problem into logical sub-problems improved its ability to understand the question in its entirety and all of the relevant context."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Jacob: \n",
       "Q: think, machine\n",
       "A: ke\n",
       "\n",
       "Q: learning, reasoning, generalization\n",
       "A: ggn\n",
       "\n",
       "Q: artificial, intelligence\n",
       "A: le\n",
       "\n",
       "Q: transformer, language, vision\n",
       "A: ren\n",
       "\n",
       "Q: foo,bar,baz,blip\n",
       "A:\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "GPT: No answer."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Example 2: Letter Concatenation\n",
    "\n",
    "# Standard prompt\n",
    "standard_prompt = \"\"\"\n",
    "Q: think, machine\n",
    "A: ke\n",
    "\n",
    "Q: learning, reasoning, generalization\n",
    "A: ggn\n",
    "\n",
    "Q: artificial, intelligence\n",
    "A: le\n",
    "\n",
    "Q: transformer, language, vision\n",
    "A: ren\n",
    "\n",
    "Q: foo,bar,baz,blip\n",
    "A:\n",
    "\"\"\"\n",
    "\n",
    "call_GPT(standard_prompt, 'text-davinci-003')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Jacob: \n",
       "Q: think, machine\n",
       "A: The last letter of \"think\" is \"k\". The last letter of \"machine\" is \"e\". So \"think, machine\" is \"ke\".\n",
       "\n",
       "Q: learning, reasoning, generalization\n",
       "A: The last letter of \"learning\" is \"g\". The last letter of \"reasoning\" is \"n\". The last letter of \"generalization\" is \"n\". So \"learning, reasoning, generalization\" is \"ggn\".\n",
       "\n",
       "Q: artificial, intelligence\n",
       "A: The last letter of \"artificial\" is \"l\". The last letter of \"intelligence\" is \"e\". So \"artificial, intelligence\" is \"le\".\n",
       "\n",
       "Q: transformer, language, vision\n",
       "A: The last letter of \"transformer\" is \"r\". The last letter of \"language\" is \"e\". The last letter of \"vision\" is \"n\". So \"transformer, language, vision\" is \"ren\".\n",
       "\n",
       "Q: foo,bar,baz,blip\n",
       "A:\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "GPT: The last letter of \"foo\" is \"o\". The last letter of \"bar\" is \"r\". The last letter of \"baz\" is \"z\". The last letter of \"blip\" is \"p\". So \"foo,bar,baz,blip\" is \"orzp\"."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Example 2: Letter Concatenation\n",
    "\n",
    "# Chain of Thought\n",
    "chain_of_thought_prompt = \"\"\"\n",
    "Q: think, machine\n",
    "A: The last letter of \"think\" is \"k\". The last letter of \"machine\" is \"e\". So \"think, machine\" is \"ke\".\n",
    "\n",
    "Q: learning, reasoning, generalization\n",
    "A: The last letter of \"learning\" is \"g\". The last letter of \"reasoning\" is \"n\". The last letter of \"generalization\" is \"n\". So \"learning, reasoning, generalization\" is \"ggn\".\n",
    "\n",
    "Q: artificial, intelligence\n",
    "A: The last letter of \"artificial\" is \"l\". The last letter of \"intelligence\" is \"e\". So \"artificial, intelligence\" is \"le\".\n",
    "\n",
    "Q: transformer, language, vision\n",
    "A: The last letter of \"transformer\" is \"r\". The last letter of \"language\" is \"e\". The last letter of \"vision\" is \"n\". So \"transformer, language, vision\" is \"ren\".\n",
    "\n",
    "Q: foo,bar,baz,blip\n",
    "A:\n",
    "\"\"\"\n",
    "\n",
    "call_GPT(chain_of_thought_prompt, 'text-davinci-003')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It worked! Although, this will start to fail on larger sized problems."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Jacob: \n",
       "Q: think, machine\n",
       "A: The last letter of \"think\" is \"k\". The last letter of \"machine\" is \"e\". Concatenating \"k\" and \"e\" gives \"ke\". So \"think, machine\" output \"ke\".\n",
       "\n",
       "Q: think, machine, learning\n",
       "A: \"think, machine\" outputs \"ke\". The last letter of \"learning\" is \"g\". Concatenating \"ke\" and \"g\" gives \"keg\". So \"think, machine, learning\" is \"keg\".\n",
       "\n",
       "Q: transformer, language\n",
       "A: The last letter of \"transformer\" is \"r\". The last letter of \"language\" is \"e\". Concatenating \"r\" and \"e\" gives \"re\". So \"transformer, language\" is \"re\".\n",
       "\n",
       "Q: transformer, language, vision\n",
       "A: \"transformer, language\" outputs \"re\". The last letter of \"vision\" is \"n\". Concatenating \"re\" and \"n\" gives \"ren\". So \"transformer, language, vision\" is \"ren\".\n",
       "\n",
       "Q: foo,bar,baz,blip,learn,prompting,world,shaking,event,dancefloor,prisma,giraffe\n",
       "A:\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "GPT: The last letter of \"foo\" is \"o\". The last letter of \"bar\" is \"r\". Concatenating \"o\" and \"r\" gives \"or\". \n",
       "The last letter of \"baz\" is \"z\". The last letter of \"blip\" is \"p\". Concatenating \"z\" and \"p\" gives \"zp\". \n",
       "The last letter of \"learn\" is \"n\". The last letter of \"prompting\" is \"g\". Concatenating \"n\" and \"g\" gives \"ng\". \n",
       "The last letter of \"world\" is \"d\". The last letter of \"shaking\" is \"g\". Concatenating \"d\" and \"g\" gives \"dg\". \n",
       "The last letter of \"event\" is \"t\". The last letter of \"dancefloor\" is \"r\". Concatenating \"t\" and \"r\" gives \"tr\". \n",
       "The last letter of \"prisma\" is \"a\". The last letter of \"giraffe\" is \"e\". Concatenating \"a\" and \"e\" gives \"ae\". \n",
       "So \"foo,bar,baz,blip,learn,prompting,world,shaking,event,dancefloor,prisma,giraffe\" is \"orzpngdgtrae\"."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Example 2: Letter Concatenation\n",
    "\n",
    "# Least to Most\n",
    "least_to_most_prompt = \"\"\"\n",
    "Q: think, machine\n",
    "A: The last letter of \"think\" is \"k\". The last letter of \"machine\" is \"e\". Concatenating \"k\" and \"e\" gives \"ke\". So \"think, machine\" output \"ke\".\n",
    "\n",
    "Q: think, machine, learning\n",
    "A: \"think, machine\" outputs \"ke\". The last letter of \"learning\" is \"g\". Concatenating \"ke\" and \"g\" gives \"keg\". So \"think, machine, learning\" is \"keg\".\n",
    "\n",
    "Q: transformer, language\n",
    "A: The last letter of \"transformer\" is \"r\". The last letter of \"language\" is \"e\". Concatenating \"r\" and \"e\" gives \"re\". So \"transformer, language\" is \"re\".\n",
    "\n",
    "Q: transformer, language, vision\n",
    "A: \"transformer, language\" outputs \"re\". The last letter of \"vision\" is \"n\". Concatenating \"re\" and \"n\" gives \"ren\". So \"transformer, language, vision\" is \"ren\".\n",
    "\n",
    "Q: foo,bar,baz,blip,learn,prompting,world,shaking,event,dancefloor,prisma,giraffe\n",
    "A:\n",
    "\"\"\"\n",
    "\n",
    "call_GPT(least_to_most_prompt, 'text-davinci-003')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see here that Least to Most prompting suceeds even at the larger sized problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Jacob: \n",
       "Q: turn left\n",
       "A: TURN LEFT\n",
       "\n",
       "Q: turn right\n",
       "A: TURN RIGHT\n",
       "\n",
       "Q: jump left\n",
       "A: TURN LEFT + JUMP\n",
       "\n",
       "Q: run right\n",
       "A: TURN RIGHT + RUN\n",
       "\n",
       "Q: look twice\n",
       "A: LOOK * 2\n",
       "\n",
       "Q: run and look twice\n",
       "A: RUN + LOOK * 2\n",
       "\n",
       "Q: jump right thrice\n",
       "A: (TURN RIGHT + JUMP) * 3\n",
       "\n",
       "Q: walk after run\n",
       "A: RUN + WALK\n",
       "\n",
       "Q: turn opposite left\n",
       "A: TURN LEFT * 2\n",
       "\n",
       "Q: turn around left\n",
       "A: TURN LEFT * 4\n",
       "\n",
       "Q: turn opposite right\n",
       "A: TURN RIGHT * 2\n",
       "\n",
       "Q: turn around right\n",
       "A: TURN RIGHT * 4\n",
       "\n",
       "Q: walk opposite left\n",
       "A: TURN LEFT * 2 + WALK\n",
       "\n",
       "Q: walk around left\n",
       "A: (TURN LEFT + WALK) * 4\n",
       "\n",
       "Q: \"jump around left twice after walk opposite left thrice\" \n",
       "A:\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "GPT: (TURN LEFT * 2 + WALK) * 3 + (TURN LEFT + JUMP) * 2"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Example 3: compositional generalization (SCAN)\n",
    "\n",
    "# Standard prompt\n",
    "standard_few_shot_prompt = \"\"\"\n",
    "Q: turn left\n",
    "A: TURN LEFT\n",
    "\n",
    "Q: turn right\n",
    "A: TURN RIGHT\n",
    "\n",
    "Q: jump left\n",
    "A: TURN LEFT + JUMP\n",
    "\n",
    "Q: run right\n",
    "A: TURN RIGHT + RUN\n",
    "\n",
    "Q: look twice\n",
    "A: LOOK * 2\n",
    "\n",
    "Q: run and look twice\n",
    "A: RUN + LOOK * 2\n",
    "\n",
    "Q: jump right thrice\n",
    "A: (TURN RIGHT + JUMP) * 3\n",
    "\n",
    "Q: walk after run\n",
    "A: RUN + WALK\n",
    "\n",
    "Q: turn opposite left\n",
    "A: TURN LEFT * 2\n",
    "\n",
    "Q: turn around left\n",
    "A: TURN LEFT * 4\n",
    "\n",
    "Q: turn opposite right\n",
    "A: TURN RIGHT * 2\n",
    "\n",
    "Q: turn around right\n",
    "A: TURN RIGHT * 4\n",
    "\n",
    "Q: walk opposite left\n",
    "A: TURN LEFT * 2 + WALK\n",
    "\n",
    "Q: walk around left\n",
    "A: (TURN LEFT + WALK) * 4\n",
    "\n",
    "Q: \"jump around left twice after walk opposite left thrice\" \n",
    "A:\n",
    "\"\"\"\n",
    "\n",
    "call_GPT(standard_few_shot_prompt, 'text-davinci-003')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Jacob: \n",
       "Q: look right after look twice\n",
       "A: \"look right after look twice\" can be solved by: \"look right\", \"look twice\".\n",
       "\n",
       "Q: jump opposite right thrice and walk\n",
       "A: \"jump opposite right thrice\" can be solved by: \"jump opposite right\", \"jump opposite right thrice\". \"walk\" can be solved by: \"walk\". So, \"jump opposite right thrice and walk\" can be solved by: \"jump opposite right\", \"jump opposite right thrice\", \"walk\".\n",
       "\n",
       "Q: run left twice and run right\n",
       "A: \"run left twice\" can be solved by: \"run left\", \"run left twice\". \"run right\" can be solved by \"run right\". So, \"run left twice and run right\" can be solved by: \"run left\", \"run left twice\", \"run right\".\n",
       "\n",
       "Q: run opposite right\n",
       "A: \"run opposite right\" can be solved by \"run opposite right\".\n",
       "\n",
       "Q: look opposite right thrice after walk\n",
       "A: \"look opposite right thrice\" can be solved by: \"look opposite right\", \"look opposite right thrice\". \"walk\" can be solved by \"walk\". So, \"look opposite right thrice after walk\" can be solved by: \"look opposite right\", \"look opposite right thrice\", \"walk\".\n",
       "\n",
       "Q: jump around right\n",
       "A: \"jump around right\" can be solved by: \"jump right\", \"jump around right\". So, \"jump around right\" can be solved by: \"jump right\", \"jump around right\".\n",
       "\n",
       "Q: look around right thrice and walk\n",
       "A: \"look around right thrice\" can be solved by: \"look right\", \"look around right\", \"look around right thrice\". \"walk\" can be solved by \"walk\". So, \"look around right thrice and walk\" can be solved by: \"look right\", \"look around right\", \"look around right thrice\", \"walk\".\n",
       "\n",
       "Q: turn right after run right thrice\n",
       "A: \"turn right\" can be solved by: \"turn right\". \"run right thrice\" can be solved by: \"run right\", \"run right thrice\". So, \"turn right after run right thrice\" can be solved by: \"turn right\", \"run right\", \"run right thrice\".\n",
       "\n",
       "Q: jump around left twice after walk opposite left thrice\n",
       "A:\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "GPT: \"jump around left twice\" can be solved by: \"jump left\", \"jump around left\", \"jump around left twice\". \"walk opposite left thrice\" can be solved by: \"walk opposite left\", \"walk opposite left thrice\". So, \"jump around left twice after walk opposite left thrice\" can be solved by: \"jump left\", \"jump around left\", \"jump around left twice\", \"walk opposite left\", \"walk opposite left thrice\"."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Example 3: compositional generalization (SCAN)\n",
    "\n",
    "# Least to Most, first step - Reduction\n",
    "# Reduce the input problem into a simpler sequence of steps\n",
    "least_to_most_first_step_prompt = \"\"\"\n",
    "Q: look right after look twice\n",
    "A: \"look right after look twice\" can be solved by: \"look right\", \"look twice\".\n",
    "\n",
    "Q: jump opposite right thrice and walk\n",
    "A: \"jump opposite right thrice\" can be solved by: \"jump opposite right\", \"jump opposite right thrice\". \"walk\" can be solved by: \"walk\". So, \"jump opposite right thrice and walk\" can be solved by: \"jump opposite right\", \"jump opposite right thrice\", \"walk\".\n",
    "\n",
    "Q: run left twice and run right\n",
    "A: \"run left twice\" can be solved by: \"run left\", \"run left twice\". \"run right\" can be solved by \"run right\". So, \"run left twice and run right\" can be solved by: \"run left\", \"run left twice\", \"run right\".\n",
    "\n",
    "Q: run opposite right\n",
    "A: \"run opposite right\" can be solved by \"run opposite right\".\n",
    "\n",
    "Q: look opposite right thrice after walk\n",
    "A: \"look opposite right thrice\" can be solved by: \"look opposite right\", \"look opposite right thrice\". \"walk\" can be solved by \"walk\". So, \"look opposite right thrice after walk\" can be solved by: \"look opposite right\", \"look opposite right thrice\", \"walk\".\n",
    "\n",
    "Q: jump around right\n",
    "A: \"jump around right\" can be solved by: \"jump right\", \"jump around right\". So, \"jump around right\" can be solved by: \"jump right\", \"jump around right\".\n",
    "\n",
    "Q: look around right thrice and walk\n",
    "A: \"look around right thrice\" can be solved by: \"look right\", \"look around right\", \"look around right thrice\". \"walk\" can be solved by \"walk\". So, \"look around right thrice and walk\" can be solved by: \"look right\", \"look around right\", \"look around right thrice\", \"walk\".\n",
    "\n",
    "Q: turn right after run right thrice\n",
    "A: \"turn right\" can be solved by: \"turn right\". \"run right thrice\" can be solved by: \"run right\", \"run right thrice\". So, \"turn right after run right thrice\" can be solved by: \"turn right\", \"run right\", \"run right thrice\".\n",
    "\n",
    "Q: jump around left twice after walk opposite left thrice\n",
    "A:\n",
    "\"\"\"\n",
    "\n",
    "call_GPT(least_to_most_first_step_prompt, 'text-davinci-003')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Jacob: \n",
       "Q: turn left\n",
       "A: \"turn left\" outputs \"TURN LEFT\".\n",
       "\n",
       "Q: turn right\n",
       "A: \"turn right\" outputs \"TURN RIGHT\".\n",
       "\n",
       "Q: jump left\n",
       "A: The output of \"jump left\" concatenates: the output of \"turn left\", the output of \"jump\". \"turn left\" outputs \"TURN LEFT\". \"jump\" outputs \"JUMP\". So concatenating the output of \"turn left\" and the out- put of \"jump\" leads to \"TURN LEFT\" + \"JUMP\". So the output of \"jump left\" is \"TURN LEFT\" + \"JUMP\".\n",
       "\n",
       "Q: run right\n",
       "A: The output of \"run right\" concatenates: the output of \"turn right\", the output of \"run\". \"turn right\" outputs \"TURN RIGHT\". \"run\" outputs \"RUN\". So concatenating the output of \"turn right\" and the output of \"run\" leads to \"TURN RIGHT\" + \"RUN\". So the output of \"run right\" is \"TURN RIGHT\" + \"RUN\".\n",
       "\n",
       "Q: look twice\n",
       "A: The output of \"look twice\" concatenates: the output of \"look\", the output of \"look\". \"look\" outputs \"LOOK\". So repeating the output of \"look\" two times leads to \"LOOK\" * 2. So the output of \"look twice\" is \"LOOK\" * 2.\n",
       "\n",
       "Q: run and look twice\n",
       "A: The output of \"run and look twice\" concatenates: the output of \"run\", the output of \"look twice\". \"run\" outputs \"RUN\". \"look twice\" outputs \"LOOK\" * 2. So concatenating the output of \"run\" and the output of \"look twice\" leads to \"RUN\" + \"LOOK\" * 2. So the output of \"run and look twice\" is \"RUN\" + \"LOOK\" * 2.\n",
       "\n",
       "Q: jump right thrice\n",
       "A: The output of \"jump right thrice\" concatenates: the output of \"jump right\", the output of \"jump right\", the output of \"jump right\". \"jump right\" outputs \"TURN RIGHT\" + \"JUMP\". So repeating the output of \"jump right\" three times leads to (\"TURN RIGHT\" + \"JUMP\") * 3. So the output of \"jump right thrice\" is (\"TURN RIGHT\" + \"JUMP\") * 3.\n",
       "\n",
       "Q: walk after run\n",
       "A: The output of \"walk after run\" concatenates: the output of \"run\", the output of \"walk\". \"run\" outputs \"RUN\". \"walk\" outputs \"WALK\". So concatenating the output of \"run\" and the output of \"walk\" leads to \"RUN\" + \"WALK\". So the output of \"walk after run\" is \"RUN\" + \"WALK\".\n",
       "\n",
       "Q: turn opposite left\n",
       "A: The output of \"turn opposite left\" concatenates: the output of \"turn left\", the output of \"turn left\". \"turn left\" outputs \"TURN LEFT\". So repeating the output of \"turn left\" twice leads to \"TURN LEFT\" * 2. So the output of \"turn opposite left\" is \"TURN LEFT\" * 2.\n",
       "\n",
       "Q: turn around left\n",
       "A: The output of \"turn around left\" concatenates: the output of \"turn left\", the output of \"turn left\", the output of \"turn left\", the output of \"turn left\". \"turn left\" outputs \"TURN LEFT\". So repeating the output of \"turn left\" four times leads to \"TURN LEFT\" * 4. So the output of \"turn around left\" is \"TURN LEFT\" * 4.\n",
       "\n",
       "Q: turn opposite right\n",
       "A: The output of \"turn opposite right\" concatenates: the output of \"turn right\", the output of \"turn right\". \"turn right\" outputs \"TURN RIGHT\". So repeating the output of \"turn right\" twice leads to \"TURN RIGHT\" * 2. So the output of \"turn opposite right\" is \"TURN RIGHT\" * 2.\n",
       "\n",
       "Q: turn around right\n",
       "A: The output of \"turn around right\" concatenates: the output of \"turn right\", the output of \"turn right\", the output of \"turn right\", the output of \"turn right\". \"turn right\" outputs \"TURN RIGHT\". So repeating the output of \"turn right\" four times leads to \"TURN RIGHT\" * 4. So the output of \"turn around right\" is \"TURN RIGHT\" * 4.\n",
       "\n",
       "Q: walk opposite left\n",
       "A: The output of \"walk opposite left\" concatenates: the output of \"turn opposite left\", the output of \"walk\". \"turn opposite left\" outputs \"TURN LEFT\" * 2. \"walk\" outputs \"WALK\". So concatenating the output of \"turn opposite left\" and the output of \"walk\" leads to \"TURN LEFT\" * 2 + \"WALK\". So the output of \"walk opposite left\" is \"TURN LEFT\" * 2 + \"WALK\".\n",
       "\n",
       "Q: walk around left\n",
       "A: The output of \"walk around left\" concatenates: the output of \"walk left\", the output of \"walk left\", the output of \"walk left\", the output of \"walk left\". \"walk left\" outputs \"TURN LEFT\" + \"WALK\". So repeating the output of \"walk around left\" four times leads to (\"TURN LEFT\" + \"WALK\") * 4. So the output of \"walk around left\" is (\"TURN LEFT\" + \"WALK\") * 4.\n",
       "\n",
       "Q: \"jump around left twice after walk opposite left thrice\" \n",
       "A:\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "GPT: \n",
       "The output of \"jump around left twice after walk opposite left thrice\" concatenates: the output of \"walk opposite left thrice\", the output of \"jump around left twice\". \"walk opposite left thrice\" outputs \"(TURN LEFT\" * 2 + \"WALK\") * 3. \"jump around left twice\" outputs (\"TURN LEFT\" + \"JUMP\") * 4. So concatenating the output of \"walk opposite left thrice\" and the output of \"jump around left twice\" leads to \"(TURN LEFT\" * 2 + \"WALK\") * 3 + (\"TURN LEFT\" + \"JUMP\") * 4. So the output of \"jump around left twice after walk opposite left thrice\" is \"(TURN LEFT\" * 2 + \"WALK\") * 3 + (\"TURN LEFT\" + \"JUMP\") * 4."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Example 3: compositional generalization (SCAN)\n",
    "\n",
    "# Least to Most, second step - Mapping\n",
    "# Map this simplified sequence of steps into actual actions\n",
    "least_to_most_second_step_prompt = \"\"\"\n",
    "Q: turn left\n",
    "A: \"turn left\" outputs \"TURN LEFT\".\n",
    "\n",
    "Q: turn right\n",
    "A: \"turn right\" outputs \"TURN RIGHT\".\n",
    "\n",
    "Q: jump left\n",
    "A: The output of \"jump left\" concatenates: the output of \"turn left\", the output of \"jump\". \"turn left\" outputs \"TURN LEFT\". \"jump\" outputs \"JUMP\". So concatenating the output of \"turn left\" and the out- put of \"jump\" leads to \"TURN LEFT\" + \"JUMP\". So the output of \"jump left\" is \"TURN LEFT\" + \"JUMP\".\n",
    "\n",
    "Q: run right\n",
    "A: The output of \"run right\" concatenates: the output of \"turn right\", the output of \"run\". \"turn right\" outputs \"TURN RIGHT\". \"run\" outputs \"RUN\". So concatenating the output of \"turn right\" and the output of \"run\" leads to \"TURN RIGHT\" + \"RUN\". So the output of \"run right\" is \"TURN RIGHT\" + \"RUN\".\n",
    "\n",
    "Q: look twice\n",
    "A: The output of \"look twice\" concatenates: the output of \"look\", the output of \"look\". \"look\" outputs \"LOOK\". So repeating the output of \"look\" two times leads to \"LOOK\" * 2. So the output of \"look twice\" is \"LOOK\" * 2.\n",
    "\n",
    "Q: run and look twice\n",
    "A: The output of \"run and look twice\" concatenates: the output of \"run\", the output of \"look twice\". \"run\" outputs \"RUN\". \"look twice\" outputs \"LOOK\" * 2. So concatenating the output of \"run\" and the output of \"look twice\" leads to \"RUN\" + \"LOOK\" * 2. So the output of \"run and look twice\" is \"RUN\" + \"LOOK\" * 2.\n",
    "\n",
    "Q: jump right thrice\n",
    "A: The output of \"jump right thrice\" concatenates: the output of \"jump right\", the output of \"jump right\", the output of \"jump right\". \"jump right\" outputs \"TURN RIGHT\" + \"JUMP\". So repeating the output of \"jump right\" three times leads to (\"TURN RIGHT\" + \"JUMP\") * 3. So the output of \"jump right thrice\" is (\"TURN RIGHT\" + \"JUMP\") * 3.\n",
    "\n",
    "Q: walk after run\n",
    "A: The output of \"walk after run\" concatenates: the output of \"run\", the output of \"walk\". \"run\" outputs \"RUN\". \"walk\" outputs \"WALK\". So concatenating the output of \"run\" and the output of \"walk\" leads to \"RUN\" + \"WALK\". So the output of \"walk after run\" is \"RUN\" + \"WALK\".\n",
    "\n",
    "Q: turn opposite left\n",
    "A: The output of \"turn opposite left\" concatenates: the output of \"turn left\", the output of \"turn left\". \"turn left\" outputs \"TURN LEFT\". So repeating the output of \"turn left\" twice leads to \"TURN LEFT\" * 2. So the output of \"turn opposite left\" is \"TURN LEFT\" * 2.\n",
    "\n",
    "Q: turn around left\n",
    "A: The output of \"turn around left\" concatenates: the output of \"turn left\", the output of \"turn left\", the output of \"turn left\", the output of \"turn left\". \"turn left\" outputs \"TURN LEFT\". So repeating the output of \"turn left\" four times leads to \"TURN LEFT\" * 4. So the output of \"turn around left\" is \"TURN LEFT\" * 4.\n",
    "\n",
    "Q: turn opposite right\n",
    "A: The output of \"turn opposite right\" concatenates: the output of \"turn right\", the output of \"turn right\". \"turn right\" outputs \"TURN RIGHT\". So repeating the output of \"turn right\" twice leads to \"TURN RIGHT\" * 2. So the output of \"turn opposite right\" is \"TURN RIGHT\" * 2.\n",
    "\n",
    "Q: turn around right\n",
    "A: The output of \"turn around right\" concatenates: the output of \"turn right\", the output of \"turn right\", the output of \"turn right\", the output of \"turn right\". \"turn right\" outputs \"TURN RIGHT\". So repeating the output of \"turn right\" four times leads to \"TURN RIGHT\" * 4. So the output of \"turn around right\" is \"TURN RIGHT\" * 4.\n",
    "\n",
    "Q: walk opposite left\n",
    "A: The output of \"walk opposite left\" concatenates: the output of \"turn opposite left\", the output of \"walk\". \"turn opposite left\" outputs \"TURN LEFT\" * 2. \"walk\" outputs \"WALK\". So concatenating the output of \"turn opposite left\" and the output of \"walk\" leads to \"TURN LEFT\" * 2 + \"WALK\". So the output of \"walk opposite left\" is \"TURN LEFT\" * 2 + \"WALK\".\n",
    "\n",
    "Q: walk around left\n",
    "A: The output of \"walk around left\" concatenates: the output of \"walk left\", the output of \"walk left\", the output of \"walk left\", the output of \"walk left\". \"walk left\" outputs \"TURN LEFT\" + \"WALK\". So repeating the output of \"walk around left\" four times leads to (\"TURN LEFT\" + \"WALK\") * 4. So the output of \"walk around left\" is (\"TURN LEFT\" + \"WALK\") * 4.\n",
    "\n",
    "Q: \"jump around left twice after walk opposite left thrice\" \n",
    "A:\n",
    "\"\"\"\n",
    "\n",
    "call_GPT(least_to_most_second_step_prompt, 'text-davinci-003')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What's in a Prompt?\n",
    "\n",
    "Some general advice about what is important in a prompt:\n",
    "\n",
    "- Surprsingly, the answers in the examplars of a few shot prompt are not very important.\n",
    "- Although the answers themselves may not be of upmost importance, having a representative labelspace of the total population is!\n",
    "- Perhaps the most important part of few shot examplars is the format!\n",
    "- Between 4-8 exemplars is a good amount to use, but the more the better given the constraints of the model context window."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
